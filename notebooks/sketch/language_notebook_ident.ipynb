{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI4Code: Language identification for notebooks by markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import fasttext\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PREDICTION_MARKDOWNS = 5 # median of count markdown cells // 2\n",
    "PROCESSING_DATA_PATH = '../../data/preprocessed/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing text function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def preprocess_text(document):\n",
    "    # Remove all the special characters\n",
    "    document = re.sub(r\"\\W\", \" \", str(document))\n",
    "\n",
    "    # remove all single characters\n",
    "    document = re.sub(r\"\\s+[a-zA-Z]\\s+\", \" \", document)\n",
    "\n",
    "    # Remove new line simbols for language identification\n",
    "    document = document.replace(\"\\n\", \" \")\n",
    "\n",
    "    # Remove html tags\n",
    "    document = re.sub(r\"<.*?>\", \"\", document)\n",
    "\n",
    "    # Remove single characters from the start\n",
    "    document = re.sub(r\"\\^[a-zA-Z]\\s+\", \" \", document)\n",
    "\n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r\"\\s+\", \" \", document, flags=re.I)\n",
    "\n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r\"^b\\s+\", \"\", document)\n",
    "\n",
    "    # Converting to Lowercase\n",
    "    document = document.lower()\n",
    "\n",
    "    # remove digits\n",
    "    document = re.sub(r\"[0-9]+\", \"\", document)\n",
    "\n",
    "    # Lemmatization\n",
    "    #tokens = document.split()\n",
    "    #tokens = [stemmer.lemmatize(word) for word in tokens]\n",
    "    #tokens = [word for word in tokens if len(word) > 2]\n",
    "\n",
    "    #preprocessed_text = \" \".join(tokens)\n",
    "    return document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageIdentification:\n",
    "    def __init__(self):\n",
    "        pretrained_lang_model = \"../../data/pretrained_models/lid.176.bin\"\n",
    "        self.model = fasttext.load_model(pretrained_lang_model)\n",
    "\n",
    "    def predict_lang(self, text):\n",
    "        text = preprocess_text(text)\n",
    "        predictions = self.model.predict(text, k=1)  # returns top 1 matching languages\n",
    "        return predictions\n",
    "\n",
    "\n",
    "language_ident = LanguageIdentification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_df = train[['id', 'cell', 'cell_type', 'source']]\n",
    "lang_df = lang_df[lang_df.cell_type == 'markdown']\n",
    "\n",
    "notebooks_ids = lang_df.id.unique()\n",
    "notebook_id = []\n",
    "notebook_lang = []\n",
    "for notebook_id in tqdm(notebooks_ids):\n",
    "    markdown_source = lang_df[lang_df.id == notebook_id].source.to_list()[:NUM_PREDICTION_MARKDOWNS]\n",
    "    markdown_source = \" \".join(markdown_source)\n",
    "    notebook_lang.append(language_ident.predict_lang(markdown_source))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebooks_lang_df = pd.DataFrame({'notebook_id': notebooks_ids, 'notebook_lang':notebook_lang})\n",
    "notebooks_lang_df.to_csv(os.path.join(PROCESSING_DATA_PATH, 'notebooks_lang.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebooks_lang_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebooks_lang_df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
